{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "\n",
    "notebook_path = \"Fusion Retrieval.ipynb\"\n",
    "\n",
    "nb = nbformat.read(notebook_path, as_version=4)\n",
    "\n",
    "if \"widgets\" in nb.metadata:\n",
    "    del nb.metadata[\"widgets\"]\n",
    "\n",
    "nbformat.write(nb, notebook_path)\n",
    "\n",
    "print(\"Fixed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 11908,
     "status": "ok",
     "timestamp": 1770119281921,
     "user": {
      "displayName": "314657023柏瑞",
      "userId": "02820414516176440519"
     },
     "user_tz": -480
    },
    "id": "pHwdZbxWUSjd",
    "outputId": "aceceba7-231a-4b9b-feca-9b1dc90c032e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-text-splitters\n",
      "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain-ollama\n",
      "  Downloading langchain_ollama-1.0.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-6.6.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-1.2.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.2)\n",
      "Collecting langchain-experimental\n",
      "  Downloading langchain_experimental-0.4.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting rank-bm25\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
      "Downloading langchain_ollama-1.0.1-py3-none-any.whl (29 kB)\n",
      "Downloading pypdf-6.6.2-py3-none-any.whl (329 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.1/329.1 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_huggingface-1.2.0-py3-none-any.whl (30 kB)\n",
      "Downloading langchain_experimental-0.4.1-py3-none-any.whl (210 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.1/210.1 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: rank-bm25, pypdf, pymupdf, langchain-text-splitters, langchain-ollama, langchain-huggingface, langchain-experimental, langchain-community, faiss-cpu\n",
      "Successfully installed faiss-cpu-1.13.2 langchain-community-0.4.1 langchain-experimental-0.4.1 langchain-huggingface-1.2.0 langchain-ollama-1.0.1 langchain-text-splitters-1.1.0 pymupdf-1.26.7 pypdf-6.6.2 rank-bm25-0.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community langchain-text-splitters langchain-ollama pypdf pymupdf langchain-huggingface sentence-transformers langchain-experimental faiss-cpu rank-bm25  --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 28874,
     "status": "ok",
     "timestamp": 1770119310799,
     "user": {
      "displayName": "314657023柏瑞",
      "userId": "02820414516176440519"
     },
     "user_tz": -480
    },
    "id": "cmcLXyn_S8MC"
   },
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528,
     "referenced_widgets": [
      "4bb129c91c8941d1b2b8394095bf17d1",
      "087c5f8994de416eb5edb452db8859e7",
      "1c8a96505acb4628ac6c3753912ee886",
      "2f39ce00925244cebb8bb4b424ff1164",
      "b7d0478bc973448cb642298eed99deb2",
      "df222f98154e4b02bcb0db47ffd7ddc7",
      "7fc350c94f2d4945b354b1f1aca8d6cc",
      "1bd0d93400154d63a23509846c4db0aa",
      "0ed403ebae6f47a2b005c5b14e1c197d",
      "4636d67804ab41499e4bee9acbaceed3",
      "45c50300496c40f8acd897743df6fa29",
      "e233d0722681438bbbab7a5398ac736b",
      "34ff0cb6db9540d5bb6e0a2f8261a9c8",
      "20c6fbbc9e1f485d8fbd637a79c02504",
      "b1d6cca13d644973a759ec9f5952d20c",
      "1dfbe066aa394076836f2902a4c7eaf8",
      "018c07d1d2eb4dffbcad9cd9a40d84c6",
      "ab772b6227434530911ad4b8111d2179",
      "3291077f94314b6a8b600ac9e65e577e",
      "2b27d517be1e439eac75eca310ea89d8",
      "467c344162d54987bc6d9d7017224a04",
      "a6ab0ca0582749a5ae582ceeb00dc4ae",
      "f227362024a84626a5cd1c55428d8356",
      "a3f2f9d9d07b4336851e4344d5eec1db",
      "4958f6a311934d74b03a205f94f98b32",
      "8401904805a443d197a0771703abf90c",
      "a6c4c113af7b48578ee24a5ea157b9f5",
      "0ae84fbe0c4341bfbb52a77e1130a8dd",
      "b357dc6736574c13ba08b00754448164",
      "1924b35fb545422897c2ea51b193095f",
      "25addc9345854d9d989690c254da51ff",
      "88d72669288e42b790a0b9e73ac47893",
      "8ec6f73354f3467c9d0df72bb34a9c73",
      "f11b84320c704719b92c7fb810f31c59",
      "10a483ea274348f8b0c39c559994fcd2",
      "e750a0a1232f4758b0a5b0d639c8750d",
      "a6947b2bb4584c3e91936184f7afd67e",
      "c01151a8521741fe913b8f23ef2e3fb9",
      "95b9db975f084029a3ae5b6ea98677a4",
      "d382ec838644439dbb0a98418a702331",
      "0dba6145ca074236adf0286a9e0441d9",
      "77421e39617f4b1e8465204896c44b87",
      "352986c8187a4b5cafd2732bf3de7e65",
      "e023db621bbf46d28a152c1a8a1012ac",
      "1f5f5631e3cc449180d55fd388c6238e",
      "cfb55922719f4712ad1a73be143cbb71",
      "68b88ff785544a0cae76f1365d236602",
      "0b779723497645aaacff4904d4d25a99",
      "5f5ed75d69d942caacc0ece7978c8801",
      "39e4e435f3f04c04b07d053a9f8f9608",
      "2e7427733f8b4fd789d72850cd743967",
      "732cbe06663b41a8873d23388c569499",
      "87c46409df5a434a995fdb03696e61ef",
      "023520a6d522408a8f212bad3bb249e1",
      "8c02b857c4ac4b37a8ef2e80a0cd16e1",
      "aee8fc1b8e32437d82e54701fb5747e7",
      "f0343891b9f24b27a54837bcd80e48a3",
      "49c10adeda6d4e61844a378df6955be1",
      "d5f83b1c54b0486ea69205aac955e396",
      "f9e6768dcd9145609ed5a14fcdf9288b",
      "600953d6a4fa412b9dce580f9c44399e",
      "0f46b1c0a97e48aaa58089dddad381c0",
      "0dcf90334fa64d859d29c131619f1a3f",
      "56846b86362347328f9b993975f3bea2",
      "bdf1151ad6e345b789eddc5e27f5474e",
      "b33aacaac4934f92a5f1f72ca5e362c4",
      "be05589887da46bcae7c1e19258f1295",
      "f02c94035d0540dea38a8400bf1a942b",
      "86d793453e644702bc59e023b2aed65e",
      "0defddd5d1054827a03c2f7e7bcbb7ba",
      "3648dbf34f424ed68b1eae014fb5d164",
      "35118b3e6ff3467a8b633b6223ced322",
      "987db344416844d29b18ecb156ac8e08",
      "679367b0e28a4faeb1b2a90f321ad147",
      "b3c0e10da0204338b8807fb25478520d",
      "2d7643718eaa4a278b9f856d0e456950",
      "7a06caafbf18457594d089522dc05187",
      "a633177492e743d7a66b1cc845532a10",
      "67c3ab808e5e45088affafdeb3584c56",
      "969b333699a44ee58267d7022f15fe14",
      "fe36a19b56fb452e9f9e255da7ed46f4",
      "961001cde94a4ec7bee62061cc84b87c",
      "4daeae7a055e45bb8880aa65a81989f5",
      "0892e7d5c397497fb080e838db88a354",
      "cc0dcb5d0804435e8549fd1e2fcd9ad9",
      "5dcb4c27d72e4faf944ad88be31c9ae7",
      "11be2ce4b8674215b1c2d8c5c11d7188",
      "92bb4e34e6334046a1bd4024e25c34b1",
      "d094ebaa6a644773af082ac68b9188c6",
      "6526a52e658845a3b0a559fd2a48b02f",
      "745c669988ca4b58b010dffd009b7934",
      "3040eef764594be7938e7c8923542a27",
      "004a2e241d4c42fcacd3117fc8bd4133",
      "b3a0c072f38344b2a0dd6fb982e7dead",
      "f2b6b95518484b1e961bfa478e91a520",
      "3bd2d753418a46cbaf7050ed7194cb1c",
      "c8801e5895e5499e8a53fe47c2eb0a82",
      "b4345e0769f645a7b37e1557197c339e",
      "472c32cd502f44b09894ffb14fc21de8",
      "74f3b1a838e84648a31d379037c2fa72",
      "a277a95d491e42359d8561857e0e108a",
      "b4c72cf0f72e4fa5b835f6bbe8e8989d",
      "b3daa714f75f4596848b50b2791b5e9c",
      "69ba0328c7ca4b39a0b7dbe4825c4988",
      "a34ca6fedba641aa9cf67398ea8ed479",
      "c3260f300bc547afbeb495b6cfe78a98",
      "f9f83b72556b45589f09c495ca10794e",
      "8d220a66ea814ecfbc160a88962aa2d5",
      "45bd6d4c3b80418292c67614083d481a",
      "6f7b90668cf14654b13cea283d9ea669",
      "9496d9e8d25f4b50adc42de969b35391",
      "f5ef333d6b8749a3a41652b31af17d0b",
      "105f52b71cdf471cb79aa31c803a1224",
      "a25dd9b985b347fdae3fba834921fcb9",
      "7a909eb2872942a198a66ea33e08db14",
      "c2ae31466d7643bb83941c7896a0f8c2",
      "dd07df8b7bfa4d288fae279307ad8f01",
      "e199a93f9c7c4e9eaab440dee4357cd4",
      "ff4f686b859a4e1a90e3180e2463aa55",
      "a43e138d177840f5afc7298fce0ce329",
      "24d6c8432e724aa3a42978223ffba1fd"
     ]
    },
    "executionInfo": {
     "elapsed": 23994,
     "status": "ok",
     "timestamp": 1770119334797,
     "user": {
      "displayName": "314657023柏瑞",
      "userId": "02820414516176440519"
     },
     "user_tz": -480
    },
    "id": "MIrlYYblUWjp",
    "outputId": "facdf699-ecee-47d9-9354-c2e8c1e4eb30"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb129c91c8941d1b2b8394095bf17d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e233d0722681438bbbab7a5398ac736b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f227362024a84626a5cd1c55428d8356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11b84320c704719b92c7fb810f31c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5f5631e3cc449180d55fd388c6238e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.19G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee8fc1b8e32437d82e54701fb5747e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/310 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be05589887da46bcae7c1e19258f1295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a633177492e743d7a66b1cc845532a10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d094ebaa6a644773af082ac68b9188c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f3b1a838e84648a31d379037c2fa72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9496d9e8d25f4b50adc42de969b35391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_model=HuggingFaceEmbeddings(\n",
    "    model_name=\"Qwen/Qwen3-Embedding-0.6B\",\n",
    "    model_kwargs={\"device\":\"cuda\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1770121533113,
     "user": {
      "displayName": "314657023柏瑞",
      "userId": "02820414516176440519"
     },
     "user_tz": -480
    },
    "id": "qmN5OpPpUXUn"
   },
   "outputs": [],
   "source": [
    "path=r\"/content/drive/MyDrive/RAG/RAG資料集/2401.15884v3.pdf\"\n",
    "chunk_size=1024\n",
    "chunk_overlap=64\n",
    "query=\"What the CRAG proposed to improve \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1770121534275,
     "user": {
      "displayName": "314657023柏瑞",
      "userId": "02820414516176440519"
     },
     "user_tz": -480
    },
    "id": "f7iKQgozUdLi"
   },
   "outputs": [],
   "source": [
    "def replace_tab_into_space(list_of_docs):\n",
    "    for doc in list_of_docs:\n",
    "        doc.page_content=doc.page_content.replace(\"\\t\",\" \")\n",
    "    return list_of_docs\n",
    "\n",
    "def encode_pdf_and_get_splits_documents(path,chunk_size,chunk_overlap):\n",
    "\n",
    "    loader=PyPDFLoader(path)\n",
    "    documents=loader.load()\n",
    "\n",
    "    splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size,chunk_overlap=chunk_overlap)\n",
    "    chunks=splitter.split_documents(documents)\n",
    "\n",
    "    clean_chunks=replace_tab_into_space(chunks)\n",
    "\n",
    "    vectorstore=FAISS.from_documents(clean_chunks,embedding_model)\n",
    "\n",
    "    return vectorstore,clean_chunks\n",
    "\n",
    "\n",
    "def create_bm25_index(documents:List[Document]) ->BM25Okapi:\n",
    "    tokenized_docs=[doc.page_content.split() for doc in documents]\n",
    "    return BM25Okapi(tokenized_docs)\n",
    "\n",
    "def show_context(context):\n",
    "    for i,c in enumerate(context):\n",
    "        print(f\"context{i+1} \")\n",
    "        print(c)\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 16005,
     "status": "ok",
     "timestamp": 1770121551604,
     "user": {
      "displayName": "314657023柏瑞",
      "userId": "02820414516176440519"
     },
     "user_tz": -480
    },
    "id": "aZa9CJ5_Ue6E"
   },
   "outputs": [],
   "source": [
    "vectorstore,clean_chunks=encode_pdf_and_get_splits_documents(\n",
    "    path,\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "bm25=create_bm25_index(clean_chunks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1770121552452,
     "user": {
      "displayName": "314657023柏瑞",
      "userId": "02820414516176440519"
     },
     "user_tz": -480
    },
    "id": "giSNi0meUfrV"
   },
   "outputs": [],
   "source": [
    "def fusion_retrieval(vectorstore, bm25, query, k=3, alpha=0.5):\n",
    "    epsilon = 1e-8\n",
    "    retriever=vectorstore.as_retriever()\n",
    "    all_docs = retriever.invoke(\"\", k=vectorstore.index.ntotal)\n",
    "    bm25_scores=bm25.get_scores(query.split()) #query的tokenizer要和前面的bm25一樣\n",
    "\n",
    "    vector_results = vectorstore.similarity_search_with_score(query, k=len(all_docs))\n",
    "    #  Normalize scores\n",
    "    vector_scores = np.array([score for _, score in vector_results])\n",
    "\n",
    "    #因為距離越短越好所以用1-X_normalization，分數越高越好所以不用\n",
    "\n",
    "    vector_scores = 1 - (vector_scores - np.min(vector_scores)) / (np.max(vector_scores) - np.min(vector_scores) + epsilon)\n",
    "\n",
    "    bm25_scores = (bm25_scores - np.min(bm25_scores)) / (np.max(bm25_scores) -  np.min(bm25_scores) + epsilon)\n",
    "\n",
    "    #  Combine scores\n",
    "    combined_scores = alpha * vector_scores + (1 - alpha) * bm25_scores\n",
    "\n",
    "    #  Rank documents\n",
    "    sorted_indices = np.argsort(combined_scores)[::-1]\n",
    "\n",
    "    #  Return top k documents\n",
    "    return [all_docs[i] for i in sorted_indices[:k]]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1770121655306,
     "user": {
      "displayName": "314657023柏瑞",
      "userId": "02820414516176440519"
     },
     "user_tz": -480
    },
    "id": "Uby_RAW4WSSj",
    "outputId": "f510a428-ca6c-492f-a83c-275d595f9734"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context1 \n",
      "retrieval evaluator is designed to assess the\n",
      "overall quality of retrieved documents for a\n",
      "query, returning a confidence degree based\n",
      "on which different knowledge retrieval ac-\n",
      "tions can be triggered. Since retrieval from\n",
      "static and limited corpora can only return sub-\n",
      "optimal documents, large-scale web searches\n",
      "are utilized as an extension for augmenting the\n",
      "retrieval results. Besides, a decompose-then-\n",
      "recompose algorithm is designed for retrieved\n",
      "documents to selectively focus on key infor-\n",
      "mation and filter out irrelevant information in\n",
      "them. CRAG is plug-and-play and can be\n",
      "seamlessly coupled with various RAG-based\n",
      "approaches. Experiments on four datasets\n",
      "covering short- and long-form generation tasks\n",
      "show that CRAG can significantly improve the\n",
      "performance of RAG-based approaches. 1\n",
      "1 Introduction\n",
      "Large language models (LLMs) have attracted\n",
      "increasing attention and exhibited impressive abili-\n",
      "ties to understand instructions and generate fluent\n",
      "language texts (Brown et al., 2020; Ouyang et al.,\n",
      "\n",
      "\n",
      "context2 \n",
      "Tianhua Zhang, Hongyin Luo, Yung-Sung Chuang, Wei\n",
      "Fang, Luc Gaitskell, Thomas Hartvigsen, Xixin Wu,\n",
      "Danny Fox, Helen Meng, and James R. Glass. 2023a.\n",
      "Interpretable unified language checking. CoRR,\n",
      "abs/2304.03728.\n",
      "Tianjun Zhang, Shishir G. Patil, Naman Jain, Sheng\n",
      "Shen, Matei Zaharia, Ion Stoica, and Joseph E.\n",
      "Gonzalez. 2024. RAFT: adapting language model to\n",
      "domain specific RAG. CoRR, abs/2403.10131.\n",
      "Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu,\n",
      "Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang,\n",
      "Yulong Chen, Longyue Wang, Anh Tuan Luu, Wei\n",
      "Bi, Freda Shi, and Shuming Shi. 2023b. Siren’s song\n",
      "in the AI ocean: A survey on hallucination in large\n",
      "language models. CoRR, abs/2309.01219.\n",
      "Qihuang Zhong, Liang Ding, Juhua Liu, Bo Du, and\n",
      "Dacheng Tao. 2023. Can chatgpt understand too? A\n",
      "comparative study on chatgpt and fine-tuned BERT.\n",
      "CoRR, abs/2302.10198.\n",
      "\n",
      "\n",
      "context3 \n",
      "Barret Zoph, Alexander Spiridonov, Ryan Sepassi,\n",
      "David Dohan, Shivani Agrawal, Mark Omernick,\n",
      "Andrew M. Dai, Thanumalayan Sankaranarayana\n",
      "Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira,\n",
      "Rewon Child, Oleksandr Polozov, Katherine Lee,\n",
      "Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark\n",
      "Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy\n",
      "Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov,\n",
      "and Noah Fiedel. 2023. Palm: Scaling language\n",
      "modeling with pathways. J. Mach. Learn. Res. ,\n",
      "24:240:1–240:113.\n",
      "Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu,\n",
      "Roberta Raileanu, Xian Li, Asli Celikyilmaz, and\n",
      "Jason Weston. 2024. Chain-of-verification reduces\n",
      "hallucination in large language models. pages 3563–\n",
      "3578.\n",
      "Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang,\n",
      "Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, Percy\n",
      "Liang, and Tatsunori B. Hashimoto. 2023. Alpaca-\n",
      "farm: A simulation framework for methods that learn\n",
      "from human feedback. CoRR, abs/2305.14387.\n",
      "Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat,\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform fusion retrieval\n",
    "top_docs = fusion_retrieval(vectorstore, bm25, query, k=3, alpha=0.1)\n",
    "docs_content = [doc.page_content for doc in top_docs]\n",
    "show_context(docs_content)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPXVkAqSJ3fg7a6XSY7sfiX",
   "gpuType": "T4",
   "mount_file_id": "1P8xh4qapM2qTd6Ugmlr52wf4LUqKzzUD",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (torch-env)",
   "language": "python",
   "name": "torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
